{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelLinear(nn.Linear):\n",
    "    def __init__(\n",
    "        self, in_features: int, out_features: int, bias: bool = True, pool=None\n",
    "    ) -> None:\n",
    "        super(ChannelLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.compute_axis = 1\n",
    "        self.pool = pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        axis_ref = len(x.shape) - 1\n",
    "        x = torch.transpose(x, self.compute_axis, axis_ref)\n",
    "        out_shape = list(x.shape)\n",
    "        out_shape[-1] = self.out_features\n",
    "        x = x.reshape(-1, x.shape[-1])\n",
    "        x = x.matmul(self.weight.t())\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias[None, :]\n",
    "        x = torch.transpose(x.view(out_shape), axis_ref, self.compute_axis)\n",
    "        if self.pool is not None:\n",
    "            x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, padding=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes, out_planes, kernel_size=3, stride=stride, padding=padding, bias=False\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, padding=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.padding == 0:\n",
    "            identity = identity[..., 1:-1, 1:-1]\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        if self.padding == 0:\n",
    "            identity = identity[..., 1:-1, 1:-1]\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, padding=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.padding == 0:\n",
    "            identity = identity[..., 1:-1, 1:-1]\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block,\n",
    "        layers,\n",
    "        num_classes=1000,\n",
    "        zero_init_residual=False,\n",
    "        stride0=2,\n",
    "        padding=1,\n",
    "        dropout=0.0,\n",
    "        gap_size=None,\n",
    "    ):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, 64, kernel_size=7, stride=stride0, padding=3 * padding, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        if dropout > 0:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=stride0, padding=padding)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], padding=padding)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, padding=padding)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, padding=padding)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, padding=padding)\n",
    "\n",
    "        if gap_size is None:\n",
    "            self.gap_size = None\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        elif gap_size < 0:\n",
    "            with torch.no_grad():\n",
    "                y = self.forward_features(\n",
    "                    torch.zeros((1, 3, -gap_size, -gap_size), dtype=torch.float32)\n",
    "                ).shape\n",
    "            print(\"gap_size:\", -gap_size, \">>\", y[-1])\n",
    "            self.gap_size = y[-1]\n",
    "            self.avgpool = nn.AvgPool2d(kernel_size=self.gap_size, stride=1, padding=0)\n",
    "        elif gap_size == 1:\n",
    "            self.gap_size = gap_size\n",
    "            self.avgpool = None\n",
    "        else:\n",
    "            self.gap_size = gap_size\n",
    "            self.avgpool = nn.AvgPool2d(kernel_size=self.gap_size, stride=1, padding=0)\n",
    "        self.num_features = 512 * block.expansion\n",
    "        self.fc = ChannelLinear(self.num_features, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, padding=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,\n",
    "                planes,\n",
    "                stride=stride,\n",
    "                downsample=downsample,\n",
    "                padding=padding,\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, padding=padding))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def change_output(self, num_classes):\n",
    "        self.fc = ChannelLinear(self.num_features, num_classes)\n",
    "        torch.nn.init.normal_(self.fc.weight.data, 0.0, 0.02)\n",
    "        return self\n",
    "\n",
    "    def change_input(self, num_inputs):\n",
    "        data = self.conv1.weight.data\n",
    "        old_num_inputs = int(data.shape[1])\n",
    "        if num_inputs > old_num_inputs:\n",
    "            times = num_inputs // old_num_inputs\n",
    "            if (times * old_num_inputs) < num_inputs:\n",
    "                times = times + 1\n",
    "            data = data.repeat(1, times, 1, 1) / times\n",
    "        elif num_inputs == old_num_inputs:\n",
    "            return self\n",
    "\n",
    "        data = data[:, :num_inputs, :, :]\n",
    "        print(self.conv1.weight.data.shape, \"->\", data.shape)\n",
    "        self.conv1.weight.data = data\n",
    "\n",
    "        return self\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def forward_head(self, x):\n",
    "        if self.avgpool is not None:\n",
    "            x = self.avgpool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        y = self.fc(x)\n",
    "        if self.gap_size is None:\n",
    "            y = torch.squeeze(torch.squeeze(y, -1), -1)\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.forward_head(x)\n",
    "        return x\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.load(\"resnet50-19c8e357.pth\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.real_dir = os.path.join(image_dir, \"0_real\") \n",
    "        self.fake_dir = os.path.join(image_dir, \"1_fake\") \n",
    "        self.real_image_names = sorted(os.listdir(self.real_dir))\n",
    "        self.fake_image_names = sorted(os.listdir(self.fake_dir))\n",
    "        self.real_size = len(self.real_image_names)\n",
    "        self.fake_size = len(self.fake_image_names)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.real_size + self.fake_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.real_size:\n",
    "            img_path = os.path.join(self.real_dir, self.real_image_names[idx])\n",
    "            label = torch.tensor(0.0)\n",
    "        else:\n",
    "            img_path = os.path.join(self.fake_dir, self.fake_image_names[idx-self.real_size])\n",
    "            label = torch.tensor(1.0)\n",
    "        image = self.rgb_loader(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def rgb_loader(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_dataset_path):\n",
    "    test_transforms = test_transforms = transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "            )\n",
    "\n",
    "    test_dataset = ImageDataset(image_dir = test_dataset_path, transform = test_transforms)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
    "\n",
    "    net.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    pbar = tqdm(enumerate(test_dataloader),\n",
    "            total=len(test_dataloader)) \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in pbar:\n",
    "            images, labels = images.to(device), labels.float().cpu().numpy()\n",
    "            \n",
    "            pred = net(images).squeeze()\n",
    "            predicted = (pred > 0.0).float().cpu().numpy()\n",
    "\n",
    "\n",
    "            y_pred.append(predicted)\n",
    "            y_true.append(labels)\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    \n",
    "    \n",
    "    return metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet50(stride0=1, dropout=0.5).change_output(1).to(device)\n",
    "net.load_state_dict(torch.load(\"model.ckpt\")['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = \"./AIGC-Detection-Dataset/AIGC-Detection-Dataset/val\"\n",
    "print(\"Accuracy: \", test(net, test_dataset_path))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
